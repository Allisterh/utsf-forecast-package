---
title: "utsf"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{utsf}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(utsf)
```

In this document the **utsf** package for univariate time series forecasting is described. This package facilitates the application of regression models in an univariate time series forecasting setting, offering a common interface for using different models.

# Univariate time series forecasting

The **utsf** package makes it easy the use of classical regression models for univariate time series forecasting. All the supported models are applied using an uniform interface: the `forecast()` function. Let us see an example of a call to this function:

```{r}
f <- forecast(AirPassengers, h = 12, lags = 1:12, method = "rt")
```

In this case, a regression tree model (`method = "rt"`) is built using the historical values of the `AirPassengers` time series and a forecast for its 12 next future values (`h = 12`) is done. The `forecast()` function returns an S3 object of class `utsf` with information about the fitted model and the forecast. The information about the forecast is included in the component `pred` as an object of class `ts` (a time series):

```{r}
f$pred
library(ggplot2)
autoplot(f)
```

The training set used to fit the model (in the previous example, a regression tree), is built from the historical values of the time series following an autoregressive approach. Each target of the training set is a historical value of the time series and its associated features or regressors are lagged values of the target, that is, previous values of the target in the series. The lagged values used (also called *lags*) are specified by the `lags` parameter of the `forecast()` function. In the example: `lags = 1:12`, so a target "is explained" by its 12 previous values. Next, we consult the first targets (and their associated features) with which the regression model has been trained:

```{r}
head(f$targets)  # first targets
head(f$features) # and its associated features
```

To clarify how the training set is built, let us use an artificial time series:

```{r}
t <- ts(c(1, 3, 6, 7, 9, 11, 16))
```

We are going to use lags 1, 2 and 4, so that a target "is explained" by its first, second and fourth previous values in the time series.

```{r}
out <- forecast(t, h = 3, lags = c(1, 2, 4), transform = "none")
cbind(out$features, Target = out$targets)
```

Given this time series and the lags `c(1, 2, 4)` the training set has three examples. The target of the first example is 9 and its features are its fourth, second and first lagged values in the series, i.e., the vector $[1, 6, 7]$. The target of the second example is 11 and its features are the vector $[3, 7, 9]$.

As in classical statistical models ARIMA and exponential smoothing, the `forecast()` function uses a recursive approach to make the predictions. The regression model is applied recursively until all horizons are forecast. For example, in the last example, the forecast horizon is 3. To forecast the next future value of the series (horizon 1) the regression model is fed with the vector $[7, 11, 16]$, which are the fourth, second and first lagged values of the next future value of the series. Let us call **F1** the forecast for horizon 1 produced by the regression model. To forecast horizon 2 the regression model is fed with the vector $[9, 16, F1]$. The forecast for horizon 1 is used as the first lagged value for horizon 2 because the actual value is unknown. Finally, to predict horizon 3 the regression model is fed with the vector [$11, F1, F2]$.

# Supported models

The `forecast()` function provides a common interface to applying univariate time series forecasting using different regression models. These models are implemented in several R packages. Currently, the `forecast()` function is mainly focused on regression trees models, incorporating the following models:

* k-nearest neighbors: In this case no model is built and the function `FNN::knn.reg()` is
  used to predict the future values of the time series.
* Regression trees: The model is built using the function `rpart::rpart()` and its 
  associated method `rpart::predict.rpart()` is applied for the forecasts.
* Model trees: The model is built with the function `Cubist::cubist()` and its associated method `Cubist::predict.cubist()` is used for predictions.
* Bagging: The model is built with the function `ipred::bagging()` and its
  associated method `ipred::predict.regbagg()` is used for forecasting.
* Random forest: The model is built with the function `ranger::ranger()` and its associated method `ranger::predict.ranger()` is used for predictions.

The `utsf` object returned by the `forecast()` function contains a component with the fitted regression model:

```{r}
f <- forecast(fdeaths, h = 12, lags = 1:12, method = "rt")
f$model
```

In this case, the model `f$model` is the result of building a regression tree model using the function `rpart::rpart()` fitted with the training set consisting of the features `f$features` and targets `f$targets`. Once the model is trained, the `rpart::predict.rpart()` function is used recursively to forecast the future values of the time series.

# Using your own models

One interesting feature of the **utsf** package is that you can use the `forecast()` function to apply your own regression models to univariate time series forecasting. In this way, your regression models can benefit from the features implemented in the `forecast()` function, such as preprocessing, parameter tuning, the building of the training set, the implementation of recursive forecasts or forecast accuracy estimation.

To use this feature you have to use the `method` parameter of the  `forecast()` function, providing a function that builds your model. This function should return the regression model and have at least two input parameters:

* `X`: it is a matrix with the features of the training examples. This matrix is built from the time series taking into account the autoregressive lags as explained in the first section. This is the same object as the `features` component of the object returned by the `forecast()` function.
* `y`: a vector with the targets of the training examples. It is built as explained in the first section. It is the same object as the `targets` component of the object returned by the `forecast()` function.

Furthermore, if the function that builds the model returns a model of class `model_class`, a method with the signature `predict.model_class(object, new_value)` should be implemented. This method uses the model to predict a new value. 

Let us see an example, in which the `forecast()` function is used to forecast a time series using a k-nearest neighbors regression model implemented in the package FNN:

```{r}
# Function to build the regression model
my_knn_model <- function(X, y, k = 3) {
  structure(list(X = X, y = y, k = k), class = "my_knn")
}

# Function to predict a new example
predict.my_knn <- function(object, new_value) {
  FNN::knn.reg(train = object$X, test = new_value, 
               y = object$y, k = object$k)$pred
}

f <- forecast(AirPassengers, h = 12, lags = 1:12, method = my_knn_model)
print(f$pred)
```

The `new_value` parameter of the `predict` method receives a data frame with the same structure as the `X` parameter of the function for building the model. However, the `new_value ` data frame only has one row, with the features of the example to be predicted.

The k-nearest neighbors algorithm is so simple that can be easily implemented without using functionality of any R package:

```{r}
# Function to build the regression model
my_knn_model2 <- function(X, y, k = 3) {
  structure(list(X = X, y = y, k = k), class = "my_knn2")
}

# Function to predict a new example
predict.my_knn2 <- function(object, new_value) {
  distances <- sapply(1:nrow(object$X), function(i) sum((object$X[i, ] - new_value)^2))
  k_nearest <- order(distances)[1:object$k]
  mean(object$y[k_nearest])
}

f2 <- forecast(AirPassengers, h = 12, lags = 1:12, method = my_knn_model2)
print(f2$pred)
```

Finally, we are going to forecast an artificial time series with a trend using a simple linear model.

```{r}
set.seed(7)
t <- 1:15 + rnorm(15, sd = 0.5) # time series
my_lm <- function(X, y) lm(y ~ ., data.frame(cbind(X, y = y)))
f <- forecast(t, h = 5, lags = 1, method = my_lm, transform = "none")
library(ggplot2)
autoplot(f)
```

In this case,  we rely on the `predict.lm` method to predict new values. Let us see, the model:

```{r}
f$model
```

In this case, the forecast for a future value is computed as $0.7914 + 1.0251Lag1$, where `Lag1` is the previous value to the future value being forecast.

# Setting the parameters of the regression models

Normally, a regression model can be configured using different parameters. By default, the models supported by the `forecast()` function are set using some specific parameters, usually the default values of the functions used to build the models (these functions are listed in a previous section). However, the user can set the parameters of the regression models using the `param` argument of the `forecast()` function. The `param` argument must be a list with the names and values of the parameters to be set. Let us see an example: 

```{r}
# A bagging model set with default parameters
f <- forecast(AirPassengers, h = 12, lags = 1:12, method = "bagging")
length(f$model$mtrees) # number of regression trees (25 by default)
# A bagging model set with 3 regression tress
f <- forecast(AirPassengers, h = 12, 
              lags = 1:12, 
              method = "bagging", 
              param = list(nbagg = 3)
)
length(f$model$mtrees) # number of regression trees
```

Of course, in order to set some specific parameters the user must consult the arguments of the function used internally by the `forecast()` function to build the model. In the example, the `ipred::ipredbagg()` function.

The following example shows how an user sets the parameters of a regression model implemented by himself/herself:

```{r}
# Function to build the model
my_knn_model <- function(X, y, k = 3) {
  structure(list(X = X, y = y, k = k), class = "my_knn")
}

# Regression function for object of class my_knn
predict.my_knn <- function(object, new_value) {
  FNN::knn.reg(train = object$X, test = new_value, 
               y = object$y, k = object$k)$pred
}

# The model is set with default parameters (k = 3)
f <- forecast(AirPassengers, h = 12, lags = 1:12,  method = my_knn_model)
print(f$model$k)
# The model is set with k = 5
f <- forecast(AirPassengers, h = 12, 
              method = my_knn_model, param = list(k = 5))
print(f$model$k)
```
