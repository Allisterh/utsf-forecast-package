---
title: "utsf"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{utsf}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(utsf)
```

In this document the **utsf** package for univariate time series forecasting is described. This package facilitates the application of regression models in an univariate time series forecasting setting, offering a common interface for using different models.

# Univariate time series forecasting

The **utsf** package makes it easy the use of classical regression models for univariate time series forecasting. All the supported models are applied using an uniform interface: the `forecast()` function. Let us see an example of how to call this function:

```{r}
f <- forecast(AirPassengers, h = 12, lags = 1:12, method = "rt")
```

In this case, a regression tree model (`method = "rt"`) is built using the historical values of the `AirPassengers` time series and a forecast for its 12 next future values (`h = 12`) is done. The `forecast()` function returns an S3 object of class `utsf` with information about the fitted model and the forecast. The information about the forecast is included in the component `pred` as an object of class `ts`:

```{r}
f$pred
library(vctsfr)
plot_ts(AirPassengers, prediction = f$pred)
```

The training set used to fit the model (in the previous example, a regression tree), is built from the historical values of the time series following an autoregressive approach. Each target of the training set is a historical value of the time series and its features or regressors are lagged values of the target, that is, previous values of the target. The lagged values used (also called *lags*) are specified by the `lags` parameter of the `forecast()` function. In the example: `lags = 1:12`, so a target "is explained" by its 12 previous values. Next, we consult the first targets (and its associated features) with which the regression model has been trained:

```{r}
head(f$targets)  # first targets
head(f$features) # and its associated features
```

To clarify how the training set is built, let us use an artificial time series:

```{r}
t <- ts(c(1, 3, 6, 7, 9, 11, 16))
```

We are going to use lags 1, 2 and 4, so that a target "is explained" by its first, second and fourth previous values in the time series.

```{r}
out <- forecast(t, h = 3, lags = c(1, 2, 4), transform = "none")
cbind(out$features, out$targets)
```

Given this time series and the lags `c(1, 2, 4)` the training set has three examples. The target of the first example is 9 and its features are its fourth, second and first lagged values in the series, i.e., the vector $[1, 6, 7]$.

As in classical ARIMA and exponential smoothing statistical models, a recursive approach is followed to make the predictions. The regression model is applied recursively until all horizons are forecast. For example, in the last example, the forecast horizon is 3. To forecast the next future value of the series (horizon 1) the regression model is fed with the vector $[7, 11, 16]$, which are the fourth, second and first lagged values of the next future value of the series. Let us call **F1** the forecast for horizon 1 produced by the regression model. To forecast horizon 2 the regression model is fed with the vector $[9, 16, F1]$. The forecast for horizon 1 is used as the first lagged value for horizon 2 because this value is unknown. Finally, for horizon 3 the regression model is fed with the vector [$11, F1, F2]$.

# Supported models

The `forecast()` function provides a common interface to applying univariate time series forecasting using different regression models. These models are implemented in several R packages. Currently, the `forecast()` function is focused on regression trees models, incorporating the following models:

* k-nearest neighbors: In this case no model is built and the function `FNN::knn.reg()` is
  used to predict the future values of the time series.
* Regression trees: The model is built using the function `rpart::rpart()` and its 
  associated method `rpart::predict.rpart()` is applied for the forecasts.
* Model trees: The model is built with the function `Cubist::cubist()` and its associated method `Cubist::predict.cubist()` is used for predictions.
* Bagging: The model is built with the function `ipred::bagging()` and its
  associated method `ipred::predict.regbagg()` is used for forecasting.
* Random forest: The model is built with the function `ranger::ranger()` and its associated method `ranger::predict.ranger()` is used for predictions.

The `utsf` object returned by the `forecast()` function contains a component with the regression model fitted:

```{r}
f <- forecast(fdeaths, h = 12, lags = 1:12, method = "rt")
f$model
```

In this case, the model `f$model` is the result of building a regression tree model using the function `rpart::rpart()` fitted with the training set consisting of the features `f$features` and targets `f$targets`. Once the model is trained, the `rpart::predict.rpart()` function is used recursively to forecast the future values of the time series.

# Using your own models

One interesting feature of the package is that you can use the `forecast()` function to apply your own regression models to univariate time series forecasting. This way your regression models can benefit from the features implemented in the `forecast()` function, such as preprocessing, parameter tuning, the building of the training set or the implementation of recursive forecasts.

To use this feature you have to use the `method` parameter of the  `forecast()` function, providing a function that builds the model. This function should return the regression model and should have at least two input parameters:

* `X`: it is a data frame with the features of the training examples. This data frame is built from the time series taking into account the autoregressive lags as explained in the first section. This is the same object as the `features` component of the object returned by the `forecast()` function).
* `y`: a vector with the targets of the training examples. It is built as explained in the first section (it is the same object as the `targets` component of the object returned by the `forecast()` function).

Furthermore, if this function returns a model of class `model_class` you have to implement a method to predict a new value: `predict.model_class(object, new_value)` using the model. Let us see an example, in which we use a k-nearest neighbors regression model implemented in the package FNN:

```{r}
# Function to build the regression model
my_knn_model <- function(X, y) {
  structure(list(X = X, y = y), class = "my_knn")
}

# Function to predict a new example
predict.my_knn <- function(object, new_value) {
  FNN::knn.reg(train = object$X, test = new_value, y = object$y)$pred
}

f <- forecast(AirPassengers, h = 12, method = my_knn_model)
print(f$pred)
```

The `new_value` parameter of the `predict` method receives a data frame with the same structure of the `X` parameter of the function for building the model. However, the `new value ` data frame always has one row.

The k-nearest neighbors is so simple that you can easily implement the regression model by yourself:

```{r}
# Function to build the regression model
my_knn_model2 <- function(X, y, k = 3) {
  structure(list(X = X, y = y, k = k), class = "my_knn2")
}

# Function to predict a new example
predict.my_knn2 <- function(object, new_value) {
  distances <- sapply(1:nrow(object$X), function(i) sum((object$X[i, ] - new_value)^2))
  k_nearest <- order(distances)[1:object$k]
  mean(object$y[k_nearest])
}

f2 <- forecast(AirPassengers, h = 12, method = my_knn_model2)
print(f2$pred)
```

# Setting the parameters of the regression models

Normally, a regression model can be configured using different parameters. By default, the models supported by the `forecast()` function are set using some specific parameters, usually the default values of the functions used to build the models (these functions are enumerated in a previous section). However, the user can set the parameters of the regression models using the `param` argument of the `forecast()` function. The `param` argument must be a list with the names and values of the parameters to be set. Let us see an example: 

```{r}
# A bagging model set with default parameters
f <- forecast(AirPassengers, h = 12, lags = 1:12, method = "bagging")
length(f$model$mtrees) # number of regression trees (25 by default)
# A bagging model set with 3 regression tress
f <- forecast(AirPassengers, h = 12, 
              lags = 1:12, 
              method = "bagging", 
              param = list(nbagg = 3)
)
length(f$model$mtrees) # number of regression trees
```

Of course, in order to set some specific parameters the user must consult the arguments of the function used internally by the `forecast()` function to build the model. In the example, the `ipred::ipredbagg()` function.

This new example shows that the users can also set the parameters of a regression model implemented by themselves:

```{r}
# Function to build the model
my_knn_model <- function(X, y, k = 3) {
  structure(list(X = X, y = y, k = k), class = "my_knn")
}

# Regression function for object of class my_knn
predict.my_knn <- function(object, new_value) {
  FNN::knn.reg(train = object$X, test = new_value, 
               y = object$y, k = object$k)$pred
}

# The model is set with default parameters (k = 3)
f <- forecast(AirPassengers, h = 12, method = my_knn_model)
print(f$model$k)
# The model is set with k = 5
f <- forecast(AirPassengers, h = 12, 
              method = my_knn_model, param = list(k = 5))
print(f$model$k)
```
